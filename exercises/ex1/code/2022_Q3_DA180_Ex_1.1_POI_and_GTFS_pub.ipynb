{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.1 - Importing Points of Interest from OpenStreetMaps and General Transit Feed Specification data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we pull data from OpenStreetMaps using the [overpass API](https://wiki.openstreetmap.org/wiki/Overpass_API). The query returns JSON which can either be loaded into the SAP HANA JSON Document Store, or \"flattened\" and loaded into a table. Both variants make use of a [hana-ml dataframe](https://help.sap.com/doc/1d0ebfe5e8dd44d09606814d83308d4b/latest/en-US/hana_ml.dataframe.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import hana_ml\n",
    "from hana_ml.dataframe import ConnectionContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HANA version: 4.00.000.00.1663064250 (fa/CE2022.30)\n",
      "hana-ml version: 2.14.22092300\n",
      "pandas version: 1.2.5\n"
     ]
    }
   ],
   "source": [
    "# Connect to SAP HANA Cloud\n",
    "host = '[YourHostName]'\n",
    "port = 443\n",
    "user = '[YourUser]'\n",
    "passwd = '[YourUserPassword]'\n",
    "cc= ConnectionContext(address=host, port=port, user=user, password=passwd, encrypt='true' ,sslValidateCertificate='false')\n",
    "\n",
    "schema=\"TECHED_USER_000\"\n",
    "print('HANA version:', cc.hana_version())\n",
    "print('hana-ml version:', hana_ml.__version__)\n",
    "print('pandas version:', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cafe|restaurant|bar amenities from 500m around Adelaide's center\n",
    "# This query pulls a rather small amount of data from OSM\n",
    "overpass_query = \"\"\"\n",
    "    [out:json];\n",
    "    (\n",
    "        node[amenity=cafe](around:500, -34.927975, 138.601394);\n",
    "        node[amenity=restaurant](around:500, -34.927975, 138.601394);\n",
    "        node[amenity=bar](around:500, -34.927975, 138.601394);\n",
    "    );\n",
    "    out geom;\n",
    "\"\"\"\n",
    "overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "response = requests.get(overpass_url, params={'data': overpass_query})\n",
    "data_small = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'node',\n",
       " 'id': 267954364,\n",
       " 'lat': -34.9245258,\n",
       " 'lon': 138.599892,\n",
       " 'tags': {'amenity': 'cafe',\n",
       "  'brand': 'Cibo Espresso',\n",
       "  'brand:wikidata': 'Q5119230',\n",
       "  'brand:wikipedia': 'en:Cibo Espresso',\n",
       "  'cuisine': 'coffee_shop',\n",
       "  'name': 'Cibo Espresso',\n",
       "  'name:en': 'Cibo Espresso',\n",
       "  'opening_hours': 'Mo-Fr 07:00-17:00; Sa 07:00-14:00; Su 08:00-12:00',\n",
       "  'phone': '+61 8 8410 4088',\n",
       "  'postal_code': '5000',\n",
       "  'takeaway': 'yes'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the result\n",
    "data_small['elements'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The overpass API resturns JSON which we can store in the HANA Document Store.\n",
    "from hana_ml.docstore import create_collection_from_elements\n",
    "coll = create_collection_from_elements(\n",
    "    connection_context = cc,\n",
    "    schema = schema,\n",
    "    collection_name = 'POI_COLLECTION_SMALL',\n",
    "    elements = data_small[\"elements\"], \n",
    "    drop_exist_coll = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>tags.amenity</th>\n",
       "      <th>tags.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>267954364</td>\n",
       "      <td>node</td>\n",
       "      <td>138.599892</td>\n",
       "      <td>-34.924526</td>\n",
       "      <td>cafe</td>\n",
       "      <td>Cibo Espresso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>389349967</td>\n",
       "      <td>node</td>\n",
       "      <td>138.605437</td>\n",
       "      <td>-34.925643</td>\n",
       "      <td>cafe</td>\n",
       "      <td>Bean Bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>389351668</td>\n",
       "      <td>node</td>\n",
       "      <td>138.603446</td>\n",
       "      <td>-34.925728</td>\n",
       "      <td>cafe</td>\n",
       "      <td>Cibo Espresso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>389353056</td>\n",
       "      <td>node</td>\n",
       "      <td>138.602958</td>\n",
       "      <td>-34.927201</td>\n",
       "      <td>cafe</td>\n",
       "      <td>Lena's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>585135535</td>\n",
       "      <td>node</td>\n",
       "      <td>138.600485</td>\n",
       "      <td>-34.932359</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>La Trattoria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  type         lon        lat tags.amenity      tags.name\n",
       "0  267954364  node  138.599892 -34.924526         cafe  Cibo Espresso\n",
       "1  389349967  node  138.605437 -34.925643         cafe       Bean Bar\n",
       "2  389351668  node  138.603446 -34.925728         cafe  Cibo Espresso\n",
       "3  389353056  node  138.602958 -34.927201         cafe         Lena's\n",
       "4  585135535  node  138.600485 -34.932359   restaurant   La Trattoria"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As an alternative, we can also flatten the JSON data into a pandas dataframe\n",
    "df_small = pd.json_normalize(data_small, record_path =['elements'])\n",
    "df_small = df_small[['id','type','lon','lat','tags.amenity','tags.name']]\n",
    "df_small.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# ... and store the flattened data in a HANA table\n",
    "from hana_ml.dataframe import create_dataframe_from_pandas\n",
    "hdf_pois_small = create_dataframe_from_pandas(\n",
    "    connection_context=cc,\n",
    "    pandas_df=df_small, \n",
    "    schema=schema,\n",
    "    table_name='POIS_SMALL', \n",
    "    geo_cols=[(\"lon\", \"lat\")], srid=4326,\n",
    "    primary_key=('id'), allow_bigint=True,\n",
    "    drop_exist_tab=True, force=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we import Adelaide's GTFS data\n",
    "https://gtfs.adelaidemetro.com.au/v1/static/latest/google_transit.zip or <br>\n",
    "https://storage.googleapis.com/storage/v1/b/mdb-latest/o/au-south-australia-adelaide-metro-gtfs-660.zip?alt=media\n",
    "\n",
    "The zip archive contains a couple of files. In this demo we import just a subset. First we read the .txt files as pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'C:/Users/D003411/Documents/GitHub/teched2022-DA180/data/gtfs/adelaide';\n",
    "\n",
    "#path = os.path.join(p, 'agency.txt')\n",
    "#df_agency = pd.read_csv(path)\n",
    "#path = os.path.join(p, 'calendar.txt')\n",
    "#df_calendar = pd.read_csv(path)\n",
    "#path = os.path.join(p, 'calendar_dates.txt')\n",
    "#df_calendarddates = pd.read_csv(path)\n",
    "#path = os.path.join(p, 'frequencies.txt')\n",
    "#df_frequencies = pd.read_csv(path)\n",
    "#path = os.path.join(p, 'pathways.txt')\n",
    "#df_pathways = pd.read_csv(path)\n",
    "path = os.path.join(p, 'routes.txt')\n",
    "df_routes = pd.read_csv(path)\n",
    "path = os.path.join(p, 'shapes.txt')\n",
    "df_shapes = pd.read_csv(path, low_memory=False)\n",
    "path = os.path.join(p, 'stop_times.txt')\n",
    "df_stoptimes = pd.read_csv(path, low_memory=False)\n",
    "path = os.path.join(p, 'stops.txt')\n",
    "df_stops = pd.read_csv(path)\n",
    "path = os.path.join(p, 'transfers.txt')\n",
    "df_transfers = pd.read_csv(path)\n",
    "path = os.path.join(p, 'trips.txt')\n",
    "df_trips = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thne we upload the data from the pandas dataframes into a HANA table using hana-ml.\n",
    "The nice thing is that pandas guesse the datatypes pretty good, and using hana-ml you can create a spatial table column directly from the lon/lat coordinates.<br>\n",
    "<i>geo_cols=[(\"stop_lon\", \"stop_lat\")], srid=4326</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.92s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.73it/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "100%|██████████| 9/9 [01:16<00:00,  8.53s/it]\n",
      "100%|██████████| 17/17 [01:45<00:00,  6.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from hana_ml.dataframe import create_dataframe_from_pandas\n",
    "hdf_routes = create_dataframe_from_pandas(\n",
    "    connection_context=cc,\n",
    "    pandas_df=df_routes, \n",
    "    schema=schema, drop_exist_tab=True, \n",
    "    table_name='GTFS_ROUTES', force=True,\n",
    "    primary_key='route_id'\n",
    "    )\n",
    "hdf_stops = create_dataframe_from_pandas(\n",
    "    connection_context=cc,\n",
    "    pandas_df=df_stops, \n",
    "    schema=schema, drop_exist_tab=True, \n",
    "    table_name='GTFS_STOPS', force=True, allow_bigint=True,\n",
    "    geo_cols=[(\"stop_lon\", \"stop_lat\")], srid=4326,\n",
    "    primary_key='stop_id'\n",
    "    )\n",
    "hdf_transfers = create_dataframe_from_pandas(\n",
    "    connection_context=cc,\n",
    "    pandas_df=df_transfers, \n",
    "    schema=schema, drop_exist_tab=True, \n",
    "    table_name='GTFS_TRANSFERS', force=True,\n",
    "    primary_key=('from_stop_id', 'to_stop_id')\n",
    "    )\n",
    "hdf_trips = create_dataframe_from_pandas(\n",
    "    connection_context=cc,\n",
    "    pandas_df=df_trips, \n",
    "    schema=schema, drop_exist_tab=True, \n",
    "    table_name='GTFS_TRIPS', force=True,\n",
    "    primary_key='trip_id'\n",
    "    )\n",
    "hdf_shapes = create_dataframe_from_pandas(\n",
    "    connection_context=cc,\n",
    "    pandas_df=df_shapes, \n",
    "    schema=schema, drop_exist_tab=True, \n",
    "    table_name='GTFS_SHAPES', force=True,\n",
    "    geo_cols=[(\"shape_pt_lon\", \"shape_pt_lat\")], srid=4326,\n",
    "    primary_key=('shape_id','shape_pt_sequence')\n",
    "    )\n",
    "hdf_stoptimes = create_dataframe_from_pandas(\n",
    "    connection_context=cc,\n",
    "    pandas_df=df_stoptimes, \n",
    "    schema=schema, drop_exist_tab=True, \n",
    "    table_name='GTFS_STOPTIMES', force=True,\n",
    "    primary_key=('trip_id', 'stop_sequence')\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('tbd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "622306dc7c28df2438293a5a5f5fac374f5d1ae3196da6cc31d07b04254d567a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
